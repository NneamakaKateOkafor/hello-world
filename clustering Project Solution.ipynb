{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AllLife Credit Card Customer Segmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective:\n",
    "### To identify different segments in the existing customer based on their spending patterns as well as past interaction with the bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Questions:\n",
    "### 1. How many different segments of customers are there?\n",
    "### 2. How are these segments different from each other?\n",
    "### 3. What are your recommendations to the bank on how to better market to and service these customers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description:\n",
    "### Data is of various customers of a bank with their credit limit, the total number of credit cards the customer has, and different channels through which customer has contacted the bank for any queries, different channels include visiting the bank, online and through a call centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np   \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# to handle data in form of rows and columns \n",
    "import pandas as pd    \n",
    "\n",
    "# importing ploting libraries\n",
    "import matplotlib.pyplot as plt   \n",
    "\n",
    "# To enable plotting graphs in Jupyter notebook\n",
    "%matplotlib inline \n",
    "\n",
    "#importing seaborn for statistical plots\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the excel file into pandas dataframe\n",
    "mydata = pd.read_excel(\"Credit Card Customer Data.xlsx\").dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate analysis, EDA and Visualization (comments and explanations of every step included) are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the body of distributions / head\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Remove id since it is redundant\n",
    "mydata.drop('Sl_No', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660, 6)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows and columns\n",
    "mydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "mydata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a value count of the missing values \n",
    "mydata.isnull().apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers discovery using Interquartile range (IQR) \n",
    "Q1 = mydata.quantile(0.25)\n",
    "Q3 = mydata.quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer Key             0\n",
       "Avg_Credit_Limit         0\n",
       "Total_Credit_Cards       0\n",
       "Total_visits_bank      100\n",
       "Total_visits_online    144\n",
       "Total_calls_made        97\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of zeros in the column\n",
    "(mydata==0).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Information of the dataset including data types\n",
    "mydata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking only the data types not the whole information\n",
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Description of the independent attributes (name, range of values observed, mean and median, standard deviation and quartiles)\n",
    "mydata.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values in each column\n",
    "mydata.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicte rows\n",
    "mydata.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Remove Customer key because it will add no value to the clustering\n",
    "mydata.drop('Customer Key', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remving duplicates\n",
    "mydata = mydata.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Avg_Credit_Limit       2.186592\n",
       "Total_Credit_Cards     0.150120\n",
       "Total_visits_bank      0.149368\n",
       "Total_visits_online    2.209521\n",
       "Total_calls_made       0.656954\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skewness of the dataset\n",
    "mydata.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg_Credit_Limit and Total_visits_online are highly skewed so i will treat the data later in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers discovery using Visualization tools (boxplot)\n",
    "sns.distplot(mydata['Avg_Credit_Limit'], kde = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are outliers in the average credit limit above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(mydata['Total_Credit_Cards'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(mydata['Total_visits_bank'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(mydata['Total_visits_online'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are outliers in the total visits online as shown in the above plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(mydata['Total_calls_made'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization using pairplot\n",
    "sns.pairplot(mydata, diag_kind='kde') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = mydata.corr()\n",
    "sns.heatmap(corr, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Findings in terms of degree of relationship between the above variables:\n",
    "\n",
    "#### - There is a negative correlation between the Avg_Credit_Limit and Total_visits_bank\n",
    "#### - Avg_Credit_Limit and Total_calls_made also have a negative correlation\n",
    "#### - Total_Credit_Cards and Total_calls_made have a negative correlation\n",
    "#### - Total_visits_bank and Total_calls_made have a negative correlation\n",
    "#### - Avg_Credit_Limit and Total_Credit_Cards have a positive correlation\n",
    "#### - Avg_Credit_Limit and Total_visits_online have a positive correlation\n",
    "#### - Total_Credit_Cards also has a positive correlation with Total_visits_bank\n",
    "#### - Total_Credit_Cards also has a positive correlation with Total_visits_online\n",
    "#### - Total_calls_made and Total_visits_online have a positive correlation\n",
    "#### - Total_visits_bank and Total_visits_online have a negative correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Treat the outliers discovered\n",
    "# mydata['Avg_Credit_Limit'] = np.log(mydata['Avg_Credit_Limit'])\n",
    "# mydata['Total_visits_online'] = np.log(mydata['Total_visits_online'])\n",
    "\n",
    "When itreated the outliers and scaled, my data became too large and prompted errors while plotting the elbow method. So, i will just state the code for the project sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Scale the data\n",
    "from scipy.stats import zscore\n",
    "mydata_z = mydata.apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding optimal no. of clusters\n",
    "\n",
    "clusters=range(1,10)\n",
    "meanDistortions=[]\n",
    "\n",
    "for k in clusters:\n",
    "    model=KMeans(n_clusters=k)\n",
    "    model.fit(mydata)\n",
    "    prediction=model.predict(mydata)\n",
    "    meanDistortions.append(sum(np.min(cdist(mydata, model.cluster_centers_, 'euclidean'), axis=1)) / mydata\n",
    "                           .shape[0])\n",
    "\n",
    "\n",
    "plt.plot(clusters, meanDistortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Average distortion')\n",
    "plt.title('Selecting k with the Elbow Method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the value of k=6\n",
    "kmeans = KMeans(n_clusters=6, n_init = 15, random_state=2345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(mydata_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the centroids for the columns to profile\n",
    "centroid_df = pd.DataFrame(centroids, columns = list(mydata_z) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centroid_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 2 has highest values for Avg_Credit_Limit while 5 has lowest\n",
    "# Group 0 has the lowest Total_Credit_Cards and 2 has the highest values\n",
    "# Group 3 has the highest number customers who visited the bank while 2 has the lowest\n",
    "# Group 2 has the highest number of customers who communicated with the bank online while group 4 has the least number\n",
    "# Group 1 made the highest number of calls to the bank while group 2 made the least calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a new dataframe only for labels and converting it into categorical variable\n",
    "df_labels = pd.DataFrame(kmeans.labels_ , columns = list(['labels']))\n",
    "\n",
    "df_labels['labels'] = df_labels['labels'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the label dataframe with the data frame.\n",
    "df_labeled = mydata_z.join(df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the groupby creates a grouped dataframe that needs to be converted back to dataframe\n",
    "df_analysis = (df_labeled.groupby(['labels'] , axis=0)).head(4177)  \n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_labeled['labels'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the 3d plot using mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 3D plots of clusters\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=20, azim=60)\n",
    "k3_model=KMeans(3)\n",
    "k3_model.fit(mydata_z)\n",
    "labels = k3_model.labels_\n",
    "ax.scatter(mydata_z.iloc[:, 0], mydata_z.iloc[:, 1], mydata_z.iloc[:, 2],c=labels.astype(np.float), edgecolor='k')\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.set_xlabel('Length')\n",
    "ax.set_ylabel('Height')\n",
    "ax.set_zlabel('Weight')\n",
    "ax.set_title('3D plot of KMeans Clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let K = 3 for the following demonstration\n",
    "final_model=KMeans(3)\n",
    "final_model.fit(mydata)\n",
    "prediction=final_model.predict(mydata)\n",
    "\n",
    "#Append the prediction \n",
    "mydata[\"GROUP\"] = prediction\n",
    "print(\"Groups Assigned : \\n\")\n",
    "mydata[[\"Total_calls_made\", \"GROUP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.boxplot(by = 'GROUP',  layout=(2,4), figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To determine the quality of customer relationship in the bank, we will check the relationship between the Avg_Credit_Limit of customers and the various channels the customers used in contacting the bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10031230969326996"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " mydata['Avg_Credit_Limit'].corr(mydata['Total_visits_bank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5513845236894896"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " mydata['Avg_Credit_Limit'].corr(mydata['Total_visits_online'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4143518934760464"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " mydata['Avg_Credit_Limit'].corr(mydata['Total_calls_made'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient above indicates that average credit limit has a positive correlation with total visits online, but has a negative coeeficient with others. So, i will use that to plot the graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mydata['Avg_Credit_Limit'], mydata['Total_visits_online'],'bo')\n",
    "z = np.polyfit(mydata['Avg_Credit_Limit'], mydata['Total_visits_online'],1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(mydata['Avg_Credit_Limit'], p(mydata['Total_visits_online']), \"r--\")\n",
    "\n",
    "#geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above graph, the data does not form a perfectly straight line. It is important to note, however, that correlation is merely\n",
    "#indicative of a relationship between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering (with different linkages) with the help of dendrogram and cophenetic coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 4)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the linkage matrix using ward\n",
    "\n",
    "Z = linkage(mydata, 'ward', metric='euclidean')\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.10000000e+02, 3.95000000e+02, 0.00000000e+00, 2.00000000e+00],\n",
       "       [5.60000000e+01, 1.75000000e+02, 0.00000000e+00, 2.00000000e+00],\n",
       "       [2.90000000e+01, 2.15000000e+02, 0.00000000e+00, 2.00000000e+00],\n",
       "       ...,\n",
       "       [1.31300000e+03, 1.31400000e+03, 3.76027041e+05, 5.18000000e+02],\n",
       "       [1.31200000e+03, 1.31500000e+03, 6.29334215e+05, 1.42000000e+02],\n",
       "       [1.31600000e+03, 1.31700000e+03, 1.09385169e+06, 6.60000000e+02]])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dendrogram for the consolidated dataframe\n",
    "plt.figure(figsize=(25, 10))\n",
    "dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the truncated dendrogram, find out the optimal distance between clusters which u want to use an input for clustering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Use truncate_mode='lastp' attribute in dendrogram function to arrive at dendrogram\n",
    "dendrogram(\n",
    "    Z,\n",
    "    truncate_mode='lastp',  # show only the last p merged clusters\n",
    "    p=3,  # show only the last p merged clusters\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_d = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this distance measure(max_d) and fcluster function to cluster the data into 3 different groups\n",
    "clusters = fcluster(Z, max_d, criterion='distance')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final dendogram with 'ward linkage'\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(18, 16))\n",
    "plt.title('Agglomerative Hierarchical Clustering Dendogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('Distance')\n",
    "Z = linkage(mydata_z, 'ward')\n",
    "dendrogram(Z,leaf_rotation=90.0,p=5,color_threshold=52,leaf_font_size=10,truncate_mode='level')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use average as linkage metric and distance as Eucledian as ff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 4)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### generate the linkage matrix\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "Z1 = linkage(mydata_z, 'average', metric='euclidean')\n",
    "Z1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 464.        ,  497.        ,    0.        ,    2.        ],\n",
       "       [ 250.        ,  361.        ,    0.        ,    2.        ],\n",
       "       [ 252.        ,  324.        ,    0.        ,    2.        ],\n",
       "       ...,\n",
       "       [   0.        , 1309.        ,    3.11135778,  387.        ],\n",
       "       [1315.        , 1316.        ,    3.25253923,  610.        ],\n",
       "       [1314.        , 1317.        ,    5.45418035,  660.        ]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "dendrogram(Z1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Use truncate_mode='lastp' attribute in dendrogram function to arrive at dendrogram\n",
    "dendrogram(\n",
    "    Z1,\n",
    "    truncate_mode='lastp',  # show only the last p merged clusters\n",
    "    p=3,  # show only the last p merged clusters\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_d = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = fcluster(Z1, max_d, criterion='distance')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 16))\n",
    "plt.title('Agglomerative Hierarchical Clustering Dendogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('Distance')\n",
    "Z1 = linkage(mydata_z, 'average')\n",
    "dendrogram(Z1,leaf_rotation=90.0,p=5,color_threshold=50,leaf_font_size=10,truncate_mode='level')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use complete as linkage metric and distance as Eucledian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 4)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### generate the linkage matrix\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "Z2 = linkage(mydata_z, 'complete', metric='euclidean')\n",
    "Z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 464.        ,  497.        ,    0.        ,    2.        ],\n",
       "       [ 250.        ,  361.        ,    0.        ,    2.        ],\n",
       "       [ 320.        ,  378.        ,    0.        ,    2.        ],\n",
       "       ...,\n",
       "       [1309.        , 1314.        ,    4.3347102 ,  397.        ],\n",
       "       [1313.        , 1316.        ,    5.95846764,  610.        ],\n",
       "       [1315.        , 1317.        ,    8.44853628,  660.        ]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "dendrogram(Z2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Use truncate_mode='lastp' attribute in dendrogram function to arrive at dendrogram\n",
    "dendrogram(\n",
    "    Z2,\n",
    "    truncate_mode='lastp',  # show only the last p merged clusters\n",
    "    p=3,  # show only the last p merged clusters\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_d = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = fcluster(Z2, max_d, criterion='distance')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 16))\n",
    "plt.title('Agglomerative Hierarchical Clustering Dendogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('Distance')\n",
    "Z2 = linkage(mydata_z, 'complete')\n",
    "dendrogram(Z2,leaf_rotation=90.0,p=5,color_threshold=50,leaf_font_size=10,truncate_mode='level')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use sklearn Agglomerative Clustering and see how is it different from scipy.cluster.hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',\n",
       "                        connectivity=None, distance_threshold=None,\n",
       "                        linkage='ward', memory=None, n_clusters=3)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AgglomerativeClustering(n_clusters=3, affinity='euclidean',  linkage='ward')\n",
    "model.fit(mydata_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L=model.labels_\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(mydata_z)  # plot points with cluster dependent colors\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(Z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(Z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the cophenetic coefficient of the hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8977080867389372"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, coph_dists = cophenet(Z, pdist(mydata_z))\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Avg Silhoutte Score of the K-means Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.36807635364871844"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(mydata_z,clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Silhouette Score is better when closer 1 and worse when closer to -1 here. -0.37 is not so great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare K-means clusters with Hierarchical clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means cluster uses elbow method while Hierarchical uses agglomerative or divisive method. In this project, i used agglomerative\n",
    "# K-means clusters can handle bid data while Hierarchical cannot\n",
    "# In K-means clustering, we can see the shape of our clusters in a 3D sphere (as depicted above) or 2D, but Hierarchical uses Dendogram as shown above\n",
    "# From the elbow method or 3D plot above you can tell how many K-means cluster are available at a glance, but in hierarchical, you have to count the number of legs after cutting the dendogram at a certain level\n",
    "# The results in K-means differ when you run the algorithm multiple times with random clusters, but in hierarchical your reslts are reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the clusters formed, tell us how is one cluster different from another and answer all the key questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between one cluster and another\n",
    "The cophenetic coefficient score of the hierarchical cluster is better than the average silhouette score of the k-means cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers to key questions\n",
    "1) There are 3 different segments of customers\n",
    "2) Some customer walk into the bank for transactions and support, another segment uses the online bank facilities while the last segment prefer to call the bank for services and resolution of their problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations to the bank on how to better market to and service these customers\n",
    "\n",
    "Based on the analysis of this data, it is clear that more customers make calls to the bank call center, followed by those who use the bank's online services.\n",
    "While planning to upgrade the service delivery model, more emphasis should be on the online platforms and the customers that visit the bankto enable more customers contact the bank through this means. \n",
    "To capture more credit card customers, the head of marketing can coach the bank staff in the call center to target the customers who use this means. they should market the credit cards more through this means because the bulk of their customers communicate with them via phone calls.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
